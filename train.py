import os
import torch
import torch.nn as nn
import torch.optim as optim
import torchaudio
import torchaudio.transforms as T
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import GradScaler, autocast
from model import AudioUpscaleModel

# === –ù–ê–°–¢–†–û–ô–ö–ò STANDARD ===
TARGET_SR = 48000      # –ò—Ç–æ–≥: 48 –∫–ì—Ü
INPUT_SR = 32000       # –í—Ö–æ–¥: 32 –∫–ì—Ü
BATCH_SIZE = 16        # –ï—Å–ª–∏ —Å–ª–∞–±–∞—è –≤–∏–¥—é—Ö–∞ –∏–ª–∏ –º–∞–ª–æ –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏ - –ø–æ–Ω–∏–∂–∞–π
NUM_EPOCHS = 350       # –≠–ø–æ—Ö–∏
LEARNING_RATE = 1e-4
MODEL_SAVE_PATH = "upscale_model_standard.pth"
TRAIN_DIR = "/home/user/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/ResonAI/train/" # –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É

class StandardDegrader:
    """–ò–º–∏—Ç–∞—Ü–∏—è 32kHz, 16bit, ~192kbps"""
    def __init__(self, device):
        self.down = T.Resample(TARGET_SR, INPUT_SR).to(device)
        self.up = T.Resample(INPUT_SR, TARGET_SR).to(device)
    
    def __call__(self, waveform):
        # 1. –†–µ–∂–µ–º —á–∞—Å—Ç–æ—Ç—É –¥–æ 32 –∫–ì—Ü
        degraded = self.down(waveform)
        
        # 2. –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ 16 –±–∏—Ç (CD –∫–∞—á–µ—Å—Ç–≤–æ)
        scale = 32767.0 # 2^15 - 1
        degraded = torch.round(degraded * scale) / scale
        
        # 3. –ò–º–∏—Ç–∞—Ü–∏—è 192 –∫–±–∏—Ç/—Å (–õ–µ–≥–∫–∏–π —à—É–º —Å–∂–∞—Ç–∏—è)
        # –®—É–º –Ω–µ–±–æ–ª—å—à–æ–π, —Ç–∞–∫ –∫–∞–∫ 192–∫–±–∏—Ç –∫–∞—á–µ—Å—Ç–≤–æ "–ø–æ–¥ –ø–∏–≤–æ –ø–æ–π–¥—ë—Ç"
        noise = torch.randn_like(degraded) * 0.0015 
        degraded = degraded + noise
        
        # 4. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞–∑–º–µ—Ä 48–∫–ì—Ü –¥–ª—è –≤—Ö–æ–¥–∞ –≤ —Å–µ—Ç—å
        return self.up(degraded)

class StandardDataset(Dataset):
    def __init__(self, root_dir):
        self.filepaths = []
        for root, _, files in os.walk(root_dir):
            for file in files:
                if file.lower().endswith((".flac", ".wav", ".mp3")):
                    self.filepaths.append(os.path.join(root, file))

    def __len__(self): return len(self.filepaths) * 4

    def __getitem__(self, idx):
        filepath = self.filepaths[idx % len(self.filepaths)]
        try:
            waveform, sr = torchaudio.load(filepath)
        except: return torch.zeros(2, TARGET_SR*2), torch.zeros(2, TARGET_SR*2)

        if sr != TARGET_SR:
            resampler = T.Resample(sr, TARGET_SR)
            waveform = resampler(waveform)

        if waveform.shape[0] == 1: waveform = waveform.repeat(2, 1)
        waveform = waveform[:2, :]

        # –ß–∞–Ω–∫ 2 —Å–µ–∫—É–Ω–¥—ã
        chunk_len = TARGET_SR * 2
        if waveform.shape[1] < chunk_len:
            waveform = torch.nn.functional.pad(waveform, (0, chunk_len - waveform.shape[1]))
        else:
            start = torch.randint(0, waveform.shape[1] - chunk_len, (1,)).item()
            waveform = waveform[:, start : start + chunk_len]

        return waveform # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∏—Å—Ç—ã–π (target), –ª–æ–º–∞—Ç—å –±—É–¥–µ–º –Ω–∞ GPU

def train():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üöÄ Training Standard (32k->48k) on {device}")
    
    degrader = StandardDegrader(device)
    dataset = StandardDataset(TRAIN_DIR)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)
    
    model = AudioUpscaleModel().to(device)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    scaler = GradScaler()
    criterion = nn.L1Loss()

    for epoch in range(NUM_EPOCHS):
        model.train()
        for i, target_cpu in enumerate(dataloader):
            target = target_cpu.to(device)
            
            with torch.no_grad():
                inp = degrader(target)
            
            optimizer.zero_grad()
            with autocast():
                output = model(inp)
                loss = criterion(output, target)
            
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            if i % 10 == 0: print(f"[Ep {epoch+1}] Step {i}, Loss: {loss.item():.5f}")

        torch.save(model.state_dict(), MODEL_SAVE_PATH)
        print(f"üíæ Saved {MODEL_SAVE_PATH}")

if __name__ == "__main__":
    train()